{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2918f0",
   "metadata": {},
   "source": [
    "# SVHN Single Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72deea55",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068c43e",
   "metadata": {},
   "source": [
    "The objective of this project is to create a robust model that can effectively recognize single digits (0-9) in images taken from Google Street View. These images come with unique challenges, such as variability in digit appearance, background clutter, and image quality, making the task notably demanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1b120",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15ba55",
   "metadata": {},
   "source": [
    "The SVHN dataset (http://ufldl.stanford.edu/housenumbers/), available in its raw form, comprises full-color images of house numbers captured from Google Street View. These images, initially in .png format, were downloaded from the official SVHN dataset repository. Accompanying the images, metadata files containing the coordinates of digit bounding boxes were also downloaded. These files are essential for the subsequent extraction of single-digit images from the larger, multi-digit compositions. s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89740e",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04fa781",
   "metadata": {},
   "source": [
    "Extraction of Single-Digit Images and labeling involved processing the images and their corresponding metadata to isolate individual digits. The metadata files provided precise coordinates for the bounding boxes surrounding each digit within the multi-digit images. Utilizing these coordinates, we used a script to crop the original images accordingly, thereby extracting single-digit images and resizing them to a uniform dimension of 32x32x3 pixels. Each extracted single-digit image was then labeled based on the digit it represented, as indicated in the metadata files.\n",
    "Normalization and One-hot Encoding\n",
    "Following the organization of the extracted and labeled images, we proceeded with the normalization of pixel values. Each pixel in the RGB images was normalized by dividing by 255, scaling the values to a [0,1] range. This normalization aids in the model's training efficiency and convergence.\n",
    "Additionally, the numerical labels were transformed into a one-hot encoded format, converting each label into a binary vector of length equal to the number of classes (10). This transformation is pivotal for aligning the labels with the softmax output layer of our CNN model, enabling a straightforward evaluation of model accuracy and loss during training.\n",
    "This repository from GitHub is used to get the matfile to csv conversion : https://github.com/prijip/Py-Gsvhn-DigitStruct-Reader.git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83627047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
